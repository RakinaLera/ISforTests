from pymystem3 import Mystem
from gram_filter import gram_filter
from ngram import train
ma = Mystem()
from random import uniform

def nachform(word):
	try:
		token = ma.analyze(word)[0]['analysis'][0]['lex']
	except (KeyError, IndexError):
		token = ''
	return token

def unirand(seq, kutoken):
	freq_, res  = 0, None
	rnd = uniform(0, 1)
	for token, freq in seq:
		if kutoken == nachform(token):
			freq_ += freq * 2
		else:
			freq_ += freq / 2
		#print(1, rnd, freq_, token, kutoken)
		if rnd < freq_:
			res = (token, nachform(token))
	if res == None:
		freq_ = 0
		for token, freq in seq:
			freq_ += freq 
			#print(2, rnd, freq_, token)
			if rnd < freq_:
				res = (token, nachform(token))
	return res
			
def generate_sentence(model, kutokens):
	phrase = ''
	t0, t1 = '$', '$'
	kut = 0
	while 1:
		_, __ = unirand(model[t0, t1], kutokens[kut])
		#print(3, __, kutokens[kut])
		if __ == kutokens[kut] and len(kutokens) > kut: kut += 1
		t0 = t1
		t1 = _
		if t1 == '$': break
		if t1 in ('.!?,;:') or t0 == '$':
			phrase += t1
		else:
			phrase += ' ' + t1
		#print(phrase)
	return phrase.capitalize()
	
if __name__ == '__main__':
	model = {('$', '$'): [('правда', 1.0)], ('$', 'правда'): [('ли', 1.0)], ('правда', 'ли'): [('что', 1.0)], ('ли', 'что'): [('гетерогенная', 0.08333333333333333), ('бумага', 0.16666666666666666), ('бытовая', 0.3333333333333333), ('стекло', 0.08333333333333333), ('древесина', 0.041666666666666664), ('резина', 0.041666666666666664), ('осень', 0.041666666666666664), ('пластмасса', 0.08333333333333333), ('пищевой', 0.041666666666666664), ('кожа', 0.041666666666666664), ('компонент', 0.041666666666666664)], ('что', 'гетерогенная'): [('смесь', 1.0)], ('гетерогенная', 'смесь'): [('является', 1.0)], ('смесь', 'является'): [('твердым', 1.0)], ('является', 'твердым'): [('бытовым', 1.0)], ('твердым', 'бытовым'): [('отходом', 1.0)], ('бытовым', 'отходом'): [('?', 1.0)], ('отходом', '?'): [('$', 1.0)], ('?', '$'): [('$', 1.0)], ('что', 'бумага'): [('является', 0.5), ('имеет', 0.25), ('результат', 0.25)], ('бумага', 'является'): [('твердым', 1.0)], ('что', 'бытовая'): [('деятельность', 1.0)], ('бытовая', 'деятельность'): [('может', 0.875), ('результат', 0.125)], ('деятельность', 'может'): [('быть', 1.0)], ('может', 'быть'): [('компонентом', 0.875), ('фактором', 0.0625), ('сезоном', 0.0625)], ('быть', 'компонентом'): [('?', 1.0)], ('компонентом', '?'): [('$', 1.0)], ('что', 'стекло'): [('может', 1.0)], ('стекло', 'может'): [('быть', 1.0)], ('что', 'древесина'): [('может', 1.0)], ('древесина', 'может'): [('быть', 1.0)], ('что', 'резина'): [('может', 1.0)], ('резина', 'может'): [('быть', 1.0)], ('быть', 'фактором'): [('?', 1.0)], ('фактором', '?'): [('$', 1.0)], ('что', 'осень'): [('может', 1.0)], ('осень', 'может'): [('быть', 1.0)], ('быть', 'сезоном'): [('?', 1.0)], ('сезоном', '?'): [('$', 1.0)], ('деятельность', 'результат'): [('твердых', 1.0)], ('результат', 'твердых'): [('бытовых', 1.0)], ('твердых', 'бытовых'): [('отходов', 1.0)], ('бытовых', 'отходов'): [('?', 1.0)], ('отходов', '?'): [('$', 1.0)], ('бумага', 'имеет'): [('твердые', 1.0)], ('имеет', 'твердые'): [('бытовые', 1.0)], ('твердые', 'бытовые'): [('отходы', 1.0)], ('бытовые', 'отходы'): [('?', 1.0)], ('отходы', '?'): [('$', 1.0)], ('что', 'пластмасса'): [('может', 1.0)], ('пластмасса', 'может'): [('быть', 1.0)], ('что', 'пищевой'): [('отход', 1.0)], ('пищевой', 'отход'): [('может', 1.0)], ('отход', 'может'): [('быть', 1.0)], ('что', 'кожа'): [('может', 1.0)], ('кожа', 'может'): [('быть', 1.0)], ('что', 'компонент'): [('имеет', 1.0)], ('компонент', 'имеет'): [('твердые', 1.0)], ('бумага', 'результат'): [('твердых', 1.0)]}
	q_templs = {'Правда ли что бытовой деятельность результат твердый бытовой отходы?': {'a': {'text': 'да', 'correct': 1}, 'b': {'text': 'нет', 'correct': 0}, 'c': {'text': 'не знаю', 'correct': 0}}, 'Правда ли что гетерогенный смесь являться твердый бытовой отходы?': {'a': {'text': 'да', 'correct': 1}, 'b': {'text': 'нет', 'correct': 0}, 'c': {'text': 'не знаю', 'correct': 0}}, 'Правда ли что бумага иметь твердый бытовой отходы?': {'a': {'text': 'да', 'correct': 0}, 'b': {'text': 'нет', 'correct': 1}, 'c': {'text': 'не знаю', 'correct': 0}}, 'Правда ли что бытовой деятельность мочь быть компонент?': {'a': {'text': 'да', 'correct': 0}, 'b': {'text': 'нет', 'correct': 1}, 'c': {'text': 'не знаю', 'correct': 0}}, 'Правда ли что пищевой отход мочь быть компонент?': {'a': {'text': 'да', 'correct': 1}, 'b': {'text': 'нет', 'correct': 0}, 'c': {'text': 'не знаю', 'correct': 0}}}
	kutokens = [['правда', 'ли', 'что', 'бытовой', 'деятельность', 'результат', 'твердый', 'бытовой', 'отходы'],['правда', 'ли', 'что', 'гетерогенный', 'смесь', 'являться', 'твердый', 'бытовой', 'отходы'],['правда', 'ли', 'что', 'бумага', 'иметь', 'твердый', 'бытовой', 'отходы'],['правда', 'ли', 'что', 'бытовой', 'деятельность', 'мочь', 'быть', 'компонент'],['правда', 'ли', 'что', 'пищевой', 'отход', 'мочь', 'быть', 'компонент']]
	questions = gram_filter(q_templs,model)
	print(generate_sentence(model,kutokens))
